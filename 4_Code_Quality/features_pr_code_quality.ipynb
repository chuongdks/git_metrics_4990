{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "149048ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./api_key.env\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da340c98",
   "metadata": {},
   "source": [
    "# Import the Hao-Li AIDev datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2df0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repositories\n",
    "repo_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/repository.parquet\")\n",
    "\n",
    "# Pull Request\n",
    "pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df6a28",
   "metadata": {},
   "source": [
    "# 1. Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89954997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the repository data for 'Java' language\n",
    "java_repo_df = repo_df[repo_df['language'] == 'Java'].copy()\n",
    "java_repo_select_df = java_repo_df[['id', 'full_name']]\n",
    "\n",
    "# Join Repo and PR table based on repo id\n",
    "merged_pr_df = pr_df.merge(\n",
    "    java_repo_select_df,\n",
    "    left_on='repo_id',\n",
    "    right_on='id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# clean up extra attribute\n",
    "merged_pr_df = merged_pr_df.drop(columns=['id_y'])\n",
    "merged_pr_df = merged_pr_df.rename(columns={'id_x':'id'})\n",
    "\n",
    "# Filter PRs that were rejected (not merged) and create a new attribute\n",
    "accepted_prs = merged_pr_df[merged_pr_df['merged_at'].notnull()]\n",
    "rejected_prs = merged_pr_df[merged_pr_df['merged_at'].isnull()]\n",
    "\n",
    "# Prepare for Merge: Rename the key column\n",
    "accepted_prs = accepted_prs[['full_name', 'number']]\n",
    "rejected_prs = rejected_prs[['full_name', 'number']]\n",
    "\n",
    "# print to csv for checking\n",
    "accepted_prs.to_csv(\"accepted_PR.csv\", index=False)\n",
    "rejected_prs.to_csv(\"rejected_PR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b13051",
   "metadata": {},
   "source": [
    "## 1.1. Split the full_name of repo into owner and repo name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14daec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dotCMS', 'core', 32609), ('apache', 'pulsar', 24542), ('dotCMS', 'core', 32771), ('dotCMS', 'core', 32561), ('microsoft', 'ApplicationInsights-Java', 4293)]\n",
      "[('dotCMS', 'core', 32656), ('dotCMS', 'core', 32657), ('dotCMS', 'core', 32658), ('dotCMS', 'core', 32659), ('dotCMS', 'core', 32660)]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Split the name and put it in a List of Dict (not needed but ehh accidentally made the method like that)\n",
    "# ============================================================\n",
    "def process_repositories(pr_df):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame by status, splits the full_name, and creates a \n",
    "    list of (owner, repo) tuples for processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Split the 'full_name' column into 'owner' and 'repo' columns\n",
    "    split_df = pr_df['full_name'].str.split('/', n=1, expand=True)\n",
    "    split_df.columns = ['owner', 'repo']\n",
    "    \n",
    "    # 2. Combine the split columns and the 'number' column into a list of tuples\n",
    "    # We use axis=1 to apply the tuple creation row-wise across the three columns\n",
    "    repositories = pd.concat([split_df, pr_df['number']], axis=1).apply(tuple, axis=1).tolist()\n",
    "    \n",
    "    # Print the first 5 results for verification\n",
    "    print(repositories[:5])\n",
    "    \n",
    "    return repositories\n",
    "\n",
    "\n",
    "ACCEPTED_PULL_REQUEST = process_repositories(accepted_prs)\n",
    "REJECTED_PULL_REQUEST = process_repositories(rejected_prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5482fa",
   "metadata": {},
   "source": [
    "# 2. Helper code block to limit the API rate request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7c42486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "def safe_request(method, url, headers=None, params=None, timeout=10, sleep_between=0.4):\n",
    "    \"\"\"\n",
    "    A rate-limit-safe GitHub request wrapper that handles:\n",
    "    - Primary rate limits (5000/hour)\n",
    "    - Secondary abuse limits (burst protection)\n",
    "    - GET and HEAD requests\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        response = requests.request(method, url, headers=headers, params=params, timeout=timeout)\n",
    "\n",
    "        # Primary rate limit\n",
    "        remaining = int(response.headers.get(\"X-RateLimit-Remaining\", 1))\n",
    "        reset_ts = int(response.headers.get(\"X-RateLimit-Reset\", time.time()))\n",
    "\n",
    "        if remaining == 0:\n",
    "            wait = max(reset_ts - int(time.time()), 10)\n",
    "            print(f\"[Primary Limit] Waiting {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "            continue\n",
    "\n",
    "        # Secondary rate limit (abuse detection)\n",
    "        if response.status_code == 403:\n",
    "            print(\"[Secondary Limit] Hit GitHub abuse limit. Backing off 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        # Success or other errors handled normally\n",
    "        if not response.ok:\n",
    "            response.raise_for_status()\n",
    "\n",
    "        # Small delay prevents triggering secondary limit\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf896a",
   "metadata": {},
   "source": [
    "# 3. Git API to extract information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06670a",
   "metadata": {},
   "source": [
    "## 3.1. API to extract git metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d928623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data retrieval... (may take a moment due to multiple API calls)\n",
      "Fetching file details for PR #32609 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 9\n",
      "Fetching file details for PR #24542 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #32771 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #32561 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 126\n",
      "Fetching file details for PR #4293 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #7783 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #7739 (Paginating 100 files/page)...\n",
      "[Primary Limit] Waiting 1246 seconds...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #4262 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #7661 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #7667 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #7779 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #7439 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #4456 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #4326 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 6\n",
      "Fetching file details for PR #4252 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #4257 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 8\n",
      "Fetching file details for PR #7801 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 27\n",
      "Fetching file details for PR #4407 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #45795 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 6\n",
      "Fetching file details for PR #35602 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #7481 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 14\n",
      "Fetching file details for PR #1360 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 11\n",
      "Fetching file details for PR #7602 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 6\n",
      "Fetching file details for PR #5438 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #4287 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #4288 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #4289 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #4290 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #7458 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 17\n",
      "Fetching file details for PR #45808 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #4317 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 9\n",
      "Fetching file details for PR #4269 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #34932 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 9\n",
      "Fetching file details for PR #4280 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #4282 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #3481 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #1361 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #34576 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 10\n",
      "Fetching file details for PR #1321 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 164\n",
      "Fetching file details for PR #2120 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #4262 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #4377 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #4471 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #7760 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 6\n",
      "Fetching file details for PR #4481 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #2115 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #35374 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 30\n",
      "Fetching file details for PR #45595 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #35347 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #1 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 0\n",
      "Fetching file details for PR #32656 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 25\n",
      "Fetching file details for PR #32657 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 18\n",
      "Fetching file details for PR #32658 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 170\n",
      "Fetching file details for PR #32659 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 185\n",
      "Fetching file details for PR #32660 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 197\n",
      "Fetching file details for PR #32661 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 214\n",
      "Fetching file details for PR #32662 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 231\n",
      "Fetching file details for PR #32663 (Paginating 100 files/page)...\n",
      "[Primary Limit] Waiting 3549 seconds...\n",
      "Finished fetching. Total files processed: 244\n",
      "Fetching file details for PR #32664 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 248\n",
      "Fetching file details for PR #8904 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 14\n",
      "Fetching file details for PR #5568 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #24145 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #7651 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #35099 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #7918 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 26\n",
      "Fetching file details for PR #7920 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #7922 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #7431 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #34153 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #4263 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 0\n",
      "Fetching file details for PR #4264 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #4265 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 22\n",
      "Fetching file details for PR #45606 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #45609 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #7662 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 504\n",
      "Fetching file details for PR #7664 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 505\n",
      "Fetching file details for PR #7666 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 4\n",
      "Fetching file details for PR #4464 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #4465 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #45451 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #7391 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #7493 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 3\n",
      "Fetching file details for PR #4311 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 8\n",
      "Fetching file details for PR #2620 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #2624 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #181 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 185\n",
      "Fetching file details for PR #182 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 7\n",
      "Fetching file details for PR #26149 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 0\n",
      "Fetching file details for PR #4324 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 6\n",
      "Fetching file details for PR #4325 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 0\n",
      "Fetching file details for PR #7798 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #4254 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 0\n",
      "Fetching file details for PR #4255 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 1\n",
      "Fetching file details for PR #7942 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #45484 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 5\n",
      "Fetching file details for PR #7535 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #217 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 0\n",
      "Fetching file details for PR #218 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #2674 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 2\n",
      "Fetching file details for PR #907 (Paginating 100 files/page)...\n",
      "Finished fetching. Total files processed: 8\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Get the files name, patch code, addition, deletion, status, and RAW URL\n",
    "# ============================================================\n",
    "def get_pr_file_details(owner: str, repo: str, pr_number: int, github_token: Optional[str] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetches the details for all files changed in a Pull Request,\n",
    "    INCLUDING the raw URL for the file content.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}/files\"\n",
    "    all_file_details = []\n",
    "    page = 1\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github.v3+json\",\n",
    "    }\n",
    "    if github_token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {github_token}\"\n",
    "\n",
    "    print(f\"Fetching file details for PR #{pr_number} (Paginating 100 files/page)...\")\n",
    "\n",
    "    while True:\n",
    "        params = {\"per_page\": 100, \"page\": page}\n",
    "        \n",
    "        try:\n",
    "            response = safe_request(\"GET\", base_url, headers=headers, params=params,)\n",
    "            response.raise_for_status()\n",
    "            files_data = response.json()\n",
    "\n",
    "            if not files_data:\n",
    "                break\n",
    "\n",
    "            for file in files_data:\n",
    "                filename = file.get('filename')\n",
    "                patch_content = file.get('patch')\n",
    "                # final_patch = patch_content if patch_content else \"NULL\"\n",
    "                raw_url = file.get('raw_url') \n",
    "                \n",
    "                # All the file metrics here\n",
    "                all_file_details.append({\n",
    "                    \"filename\": filename,\n",
    "                    #\"patch\": final_patch,\n",
    "                    \"status\": file.get('status'),\n",
    "                    #\"additions\": file.get('additions', 0),\n",
    "                    #\"deletions\": file.get('deletions', 0),\n",
    "                    \"raw_url\": raw_url \n",
    "                })\n",
    "            \n",
    "            # Check for the next page header\n",
    "            if 'link' not in response.headers or 'rel=\"next\"' not in response.headers['link']:\n",
    "                break\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error during API call on page {page}: {e}\")\n",
    "            break\n",
    "            \n",
    "    print(f\"Finished fetching. Total files processed: {len(all_file_details)}\")\n",
    "    return all_file_details\n",
    "        \n",
    "# ============================================================\n",
    "# Main Helper: Fetch the main metric functions \n",
    "# ============================================================\n",
    "def fetch_metrics(repo_list, token):\n",
    "    results = []\n",
    "    # limit the number of repositories processed here for testing REPOSITORIES[:10]:\n",
    "    for owner, repo, pr_number in repo_list[:50]: # Apply the test limit here\n",
    "        metrics = get_pr_file_details(owner, repo, pr_number, token)\n",
    "        if metrics:\n",
    "            results.append(metrics)\n",
    "    \n",
    "    # Create the Metric DataFrame\n",
    "    return results # Return a List[List[Dict]] to be process later\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROGRAM\n",
    "# ============================================================\n",
    "print(\"\\nStarting data retrieval... (may take a moment due to multiple API calls)\")\n",
    "files_list_accepted = fetch_metrics(ACCEPTED_PULL_REQUEST, GITHUB_TOKEN)\n",
    "files_list_rejected = fetch_metrics(REJECTED_PULL_REQUEST, GITHUB_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab384eb",
   "metadata": {},
   "source": [
    "## 3.2. Restructure the File List and Filter the Java files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df53fa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting filtering and sorting\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Filter and Aggregate PR Data\n",
    "# ============================================================\n",
    "def filter_and_aggregate_pr_data(pr_files_list: List[List[Dict]], repo_list: List[Tuple[str, str, int]]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Filters file details for Java files that are not deleted and aggregates the \n",
    "    relevant data (like raw_urls) at the Pull Request level.\n",
    "\n",
    "    Args:\n",
    "        pr_files_list: The nested list of file details from the GitHub API.\n",
    "        repo_list: The original list of (owner, repo, pr_number) tuples \n",
    "                   used to fetch the data.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, one for each PR, containing aggregated metrics.\n",
    "    \"\"\"\n",
    "    aggregated_pr_data = []\n",
    "    \n",
    "    # Iterate through the results for each PR\n",
    "    for pr_index, pr_files in enumerate(pr_files_list):\n",
    "        \n",
    "        # Safely retrieve metadata for the current PR\n",
    "        if pr_index >= len(repo_list):\n",
    "            print(f\"Warning: Missing metadata for PR at index {pr_index}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        owner, repo, pr_number = repo_list[pr_index]\n",
    "        \n",
    "        java_files_to_analyze = []\n",
    "        \n",
    "        # --- File-level filtering ---\n",
    "        for file in pr_files:\n",
    "            filename = file.get('filename', '')\n",
    "            status = file.get('status', '')\n",
    "            \n",
    "            # 1. Detect .java file in the file name (case-insensitive)\n",
    "            is_java = filename.lower().endswith('.java')\n",
    "            \n",
    "            # 2. Exclude status deleted (we only analyze added or modified code)\n",
    "            is_not_deleted = status != 'deleted'\n",
    "            \n",
    "            # Store the file name and raw URL for the non-deleted Java file\n",
    "            if is_java and is_not_deleted:\n",
    "                java_files_to_analyze.append({\n",
    "                    \"file_name\": filename,\n",
    "                    \"raw_url\": file.get('raw_url')\n",
    "                })\n",
    "        \n",
    "        # --- PR-level aggregation ---\n",
    "        aggregated_pr_data.append({\n",
    "            'owner': owner,\n",
    "            'repo': repo,\n",
    "            'pr_number': pr_number,\n",
    "            'java_files_analyzed_count': len(java_files_to_analyze),\n",
    "            'files_to_analyze': java_files_to_analyze, # List[Dict]\n",
    "            # add the PMD violation counts later\n",
    "            'pmd_violations': {} \n",
    "        })\n",
    "        \n",
    "    return aggregated_pr_data\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROGRAM: \n",
    "# ============================================================\n",
    "print(\"\\nStarting filtering and sorting\")\n",
    "pr_code_metrics_filtered_accepted = filter_and_aggregate_pr_data(files_list_accepted, ACCEPTED_PULL_REQUEST)\n",
    "pr_code_metrics_filtered_rejected = filter_and_aggregate_pr_data(files_list_accepted, ACCEPTED_PULL_REQUEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803e0e8",
   "metadata": {},
   "source": [
    "## 3.3. Download the changed Java files and do PMD static code analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afbc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing PR: dotCMS/core #32609 (0 files) ---\n",
      "\n",
      "--- Processing PR: apache/pulsar #24542 (4 files) ---\n",
      "\n",
      "--- Processing PR: dotCMS/core #32771 (0 files) ---\n",
      "\n",
      "--- Processing PR: dotCMS/core #32561 (118 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4293 (1 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7783 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7739 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4262 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7661 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7667 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7779 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7439 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4456 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4326 (6 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4252 (2 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4257 (5 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7801 (19 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4407 (0 files) ---\n",
      "\n",
      "--- Processing PR: Azure/azure-sdk-for-java #45795 (5 files) ---\n",
      "\n",
      "--- Processing PR: camunda/camunda #35602 (4 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7481 (0 files) ---\n",
      "\n",
      "--- Processing PR: EduMIPS64/edumips64 #1360 (11 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7602 (0 files) ---\n",
      "\n",
      "--- Processing PR: apolloconfig/apollo #5438 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4287 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4288 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4289 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4290 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7458 (0 files) ---\n",
      "\n",
      "--- Processing PR: Azure/azure-sdk-for-java #45808 (0 files) ---\n",
      "\n",
      "--- Processing PR: objectionary/eo #4317 (7 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4269 (3 files) ---\n",
      "\n",
      "--- Processing PR: camunda/camunda #34932 (9 files) ---\n",
      "\n",
      "--- Processing PR: objectionary/eo #4280 (1 files) ---\n",
      "\n",
      "--- Processing PR: objectionary/eo #4282 (0 files) ---\n",
      "\n",
      "--- Processing PR: 1c-syntax/bsl-language-server #3481 (2 files) ---\n",
      "\n",
      "--- Processing PR: EduMIPS64/edumips64 #1361 (0 files) ---\n",
      "\n",
      "--- Processing PR: camunda/camunda #34576 (9 files) ---\n",
      "\n",
      "--- Processing PR: wgzhao/Addax #1321 (0 files) ---\n",
      "\n",
      "--- Processing PR: OWASP/wrongsecrets #2120 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4262 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4377 (1 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4471 (0 files) ---\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7760 (0 files) ---\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4481 (0 files) ---\n",
      "\n",
      "--- Processing PR: OWASP/wrongsecrets #2115 (0 files) ---\n",
      "\n",
      "--- Processing PR: camunda/camunda #35374 (30 files) ---\n",
      "\n",
      "--- Processing PR: Azure/azure-sdk-for-java #45595 (0 files) ---\n",
      "\n",
      "--- Processing PR: camunda/camunda #35347 (3 files) ---\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Download the java files\n",
    "# ============================================================\n",
    "def download_file(raw_url, local_path, token=None):\n",
    "    \"\"\"Downloads a single file from GitHub's raw URL.\"\"\"\n",
    "    headers = {}\n",
    "    if token:\n",
    "        headers['Authorization'] = f\"token {token}\"\n",
    "        \n",
    "    response = requests.get(raw_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        \n",
    "        with open(local_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(response.text)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to download {raw_url}. Status: {response.status_code}\")\n",
    "        return False\n",
    "    \n",
    "# ============================================================\n",
    "# Helper: Run PMD static code analyzer\n",
    "# ============================================================\n",
    "PMD_EXECUTABLE = \"pmd.bat\"\n",
    "RULESET_PATH = \"D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml\"\n",
    "BASE_STAGING_DIR = \"./pr_analysis_staging\"\n",
    "\n",
    "def run_pmd_for_pr(owner: str, repo: str, pr_number: int, ruleset_path: str = RULESET_PATH) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Runs PMD on the staging directory for a specific Pull Request.\n",
    "\n",
    "    Args:\n",
    "        owner: The repository owner.\n",
    "        repo: The repository name.\n",
    "        pr_number: The Pull Request number.\n",
    "        ruleset_path: Path to the PMD ruleset XML file.\n",
    "\n",
    "    Returns:\n",
    "        The path to the generated XML report file, or None if the analysis failed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dynamically define the source directory based on the download structure\n",
    "    source_dir = os.path.join(BASE_STAGING_DIR, owner, repo, str(pr_number))\n",
    "    \n",
    "    # Define a unique output file path inside the PR's staging folder\n",
    "    output_file_name = f\"pmd_report_{pr_number}.xml\"\n",
    "    output_file_path = os.path.join(source_dir, output_file_name)\n",
    "\n",
    "    # 1. Construct the PMD command\n",
    "    pmd_command = [\n",
    "        PMD_EXECUTABLE,\n",
    "        \"check\",\n",
    "        \"-d\", source_dir,\n",
    "        \"-R\", ruleset_path,\n",
    "        \"-f\", \"xml\",\n",
    "        \"-r\", output_file_path\n",
    "    ]\n",
    "    \n",
    "    print(f\"Executing PMD for PR #{pr_number}: {' '.join(pmd_command)}\")\n",
    "\n",
    "    try:\n",
    "        # 2. Execute the command\n",
    "        result = subprocess.run(\n",
    "            pmd_command, \n",
    "            capture_output=True, \n",
    "            text=True, \n",
    "            check=False # PMD returns exit code 4 on violations\n",
    "        )\n",
    "        \n",
    "        # Check success (0 or 4)\n",
    "        if result.returncode == 0 or result.returncode == 4:\n",
    "            print(f\"PMD analysis completed. Report saved to: {output_file_path}\")\n",
    "            return output_file_path\n",
    "        else:\n",
    "            print(f\"PMD command failed (code {result.returncode}). Error:\\n{result.stderr}\")\n",
    "            return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: PMD executable '{PMD_EXECUTABLE}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during PMD execution: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# Helper: Extract violation rules from the xml file and count them\n",
    "# ============================================================\n",
    "def parse_pmd_report_to_counts(xml_file_path: str, pr_number: int) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parses a PMD XML report, counts the violations for each unique rule, \n",
    "    and formats the result as a dictionary suitable for a DataFrame row.\n",
    "\n",
    "    Args:\n",
    "        xml_file_path: The full path to the generated PMD XML report.\n",
    "        pr_number: The Pull Request number, added as an identifier in the output.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of rule counts (e.g., {'pr_number': 123, 'ruleid_avoidusingvolatile': 1}), \n",
    "        or None if the file cannot be parsed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(xml_file_path):\n",
    "        print(f\"Error: PMD report not found at {xml_file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Handle the XML namespace (necessary for PMD reports)\n",
    "        # Extracts the namespace URL from the root tag\n",
    "        namespace_match = root.tag.split('}')\n",
    "        namespace = namespace_match[0] + '}' if len(namespace_match) > 1 else ''\n",
    "\n",
    "        # XPath to find all 'violation' elements within 'file' elements\n",
    "        violation_elements = root.findall(f\"{namespace}file/{namespace}violation\")\n",
    "\n",
    "        rule_ids = []\n",
    "        for violation in violation_elements:\n",
    "            # The rule ID is stored in the 'rule' attribute\n",
    "            rule_id = violation.get('rule')\n",
    "            if rule_id:\n",
    "                rule_ids.append(rule_id)\n",
    "\n",
    "        # 1. Count the Rules\n",
    "        rule_counts = Counter(rule_ids)\n",
    "\n",
    "        # 2. Format the Output Dictionary\n",
    "        formatted_data = {}\n",
    "        \n",
    "        # Add PR number for merging with other datasets\n",
    "        formatted_data['pr_number'] = pr_number\n",
    "        \n",
    "        #\n",
    "        for rule, count in rule_counts.items():\n",
    "            # Standardize and prefix the rule name\n",
    "            # Note: This simple standardization handles the core formatting.\n",
    "            sanitized_rule_name = rule.lower().replace(' ', '_').replace('-', '_')\n",
    "            formatted_data[f\"ruleid_{sanitized_rule_name}\"] = count\n",
    "\n",
    "        return formatted_data\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML file {xml_file_path}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during parsing: {e}\")\n",
    "        return None\n",
    "    \n",
    "# ============================================================\n",
    "# Main: Download the changed files of the PR\n",
    "# ============================================================\n",
    "for pr_data in pr_code_metrics_filtered_accepted:\n",
    "    owner = pr_data['owner']\n",
    "    repo = pr_data['repo']\n",
    "    pr_number = pr_data['pr_number']\n",
    "    files_to_analyze = pr_data['files_to_analyze'] \n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. Checkout the PR branch and download the right changed files\n",
    "    # ------------------------------------------------------------------\n",
    "    # Create a local staging directory structure. Prevents file path clashes and organizes your PMD reports\n",
    "    base_dir = \"./pr_analysis_staging\"\n",
    "    local_staging_dir = os.path.join(base_dir, owner, repo, str(pr_number))\n",
    "    \n",
    "    print(f\"\\n--- Processing PR: {owner}/{repo} #{pr_number} ({len(files_to_analyze)} files) ---\")\n",
    "    \n",
    "    # Inner loop: Iterate over the list of file dictionaries\n",
    "    for file_data in files_to_analyze:\n",
    "        # Get the two keys you need from the file dictionary\n",
    "        file_name = file_data['file_name']\n",
    "        raw_url = file_data['raw_url']\n",
    "        \n",
    "        # Determine the full local path for this file\n",
    "        local_path = os.path.join(local_staging_dir, file_name)\n",
    "        download_file(raw_url, local_path, GITHUB_TOKEN)\n",
    "        \n",
    "for pr_data in pr_code_metrics_filtered_rejected:\n",
    "    owner = pr_data['owner']\n",
    "    repo = pr_data['repo']\n",
    "    pr_number = pr_data['pr_number']\n",
    "    files_to_analyze = pr_data['files_to_analyze'] \n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. Checkout the PR branch and download the right changed files\n",
    "    # ------------------------------------------------------------------\n",
    "    # Create a local staging directory structure. Prevents file path clashes and organizes your PMD reports\n",
    "    base_dir = \"./pr_analysis_staging\"\n",
    "    local_staging_dir = os.path.join(base_dir, owner, repo, str(pr_number))\n",
    "    \n",
    "    print(f\"\\n--- Processing PR: {owner}/{repo} #{pr_number} ({len(files_to_analyze)} files) ---\")\n",
    "    \n",
    "    # Inner loop: Iterate over the list of file dictionaries\n",
    "    for file_data in files_to_analyze:\n",
    "        # Get the two keys you need from the file dictionary\n",
    "        file_name = file_data['file_name']\n",
    "        raw_url = file_data['raw_url']\n",
    "        \n",
    "        # Determine the full local path for this file\n",
    "        local_path = os.path.join(local_staging_dir, file_name)\n",
    "        download_file(raw_url, local_path, GITHUB_TOKEN)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ee739",
   "metadata": {},
   "source": [
    "### 3.3.1. Run PMD and count the violations rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing PR: dotCMS/core #32609 (0 files) ---\n",
      "Executing PMD for PR #32609: pmd.bat check -d ./pr_analysis_staging\\dotCMS\\core\\32609 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\dotCMS\\core\\32609\\pmd_report_32609.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\dotCMS\\core\\32609\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\dotCMS\\core\\32609\\pmd_report_32609.xml\n",
      "\n",
      "Skipping filtering for PR #32609 due to PMD failure.\n",
      "\n",
      "--- Processing PR: apache/pulsar #24542 (4 files) ---\n",
      "Executing PMD for PR #24542: pmd.bat check -d ./pr_analysis_staging\\apache\\pulsar\\24542 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\apache\\pulsar\\24542\\pmd_report_24542.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\apache\\pulsar\\24542\\pmd_report_24542.xml\n",
      "\n",
      "--- Processing PR: dotCMS/core #32771 (0 files) ---\n",
      "Executing PMD for PR #32771: pmd.bat check -d ./pr_analysis_staging\\dotCMS\\core\\32771 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\dotCMS\\core\\32771\\pmd_report_32771.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\dotCMS\\core\\32771\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\dotCMS\\core\\32771\\pmd_report_32771.xml\n",
      "\n",
      "Skipping filtering for PR #32771 due to PMD failure.\n",
      "\n",
      "--- Processing PR: dotCMS/core #32561 (118 files) ---\n",
      "Executing PMD for PR #32561: pmd.bat check -d ./pr_analysis_staging\\dotCMS\\core\\32561 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\dotCMS\\core\\32561\\pmd_report_32561.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\dotCMS\\core\\32561\\pmd_report_32561.xml\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4293 (1 files) ---\n",
      "Executing PMD for PR #4293: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4293 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4293\\pmd_report_4293.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4293\\pmd_report_4293.xml\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7783 (0 files) ---\n",
      "Executing PMD for PR #7783: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7783 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7783\\pmd_report_7783.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7783\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7783\\pmd_report_7783.xml\n",
      "\n",
      "Skipping filtering for PR #7783 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7739 (0 files) ---\n",
      "Executing PMD for PR #7739: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7739 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7739\\pmd_report_7739.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7739\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7739\\pmd_report_7739.xml\n",
      "\n",
      "Skipping filtering for PR #7739 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4262 (0 files) ---\n",
      "Executing PMD for PR #4262: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4262 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4262\\pmd_report_4262.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4262\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4262\\pmd_report_4262.xml\n",
      "\n",
      "Skipping filtering for PR #4262 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7661 (0 files) ---\n",
      "Executing PMD for PR #7661: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7661 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7661\\pmd_report_7661.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7661\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7661\\pmd_report_7661.xml\n",
      "\n",
      "Skipping filtering for PR #7661 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7667 (0 files) ---\n",
      "Executing PMD for PR #7667: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7667 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7667\\pmd_report_7667.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7667\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7667\\pmd_report_7667.xml\n",
      "\n",
      "Skipping filtering for PR #7667 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7779 (0 files) ---\n",
      "Executing PMD for PR #7779: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7779 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7779\\pmd_report_7779.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7779\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7779\\pmd_report_7779.xml\n",
      "\n",
      "Skipping filtering for PR #7779 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7439 (0 files) ---\n",
      "Executing PMD for PR #7439: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7439 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7439\\pmd_report_7439.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7439\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7439\\pmd_report_7439.xml\n",
      "\n",
      "Skipping filtering for PR #7439 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4456 (0 files) ---\n",
      "Executing PMD for PR #4456: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4456 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4456\\pmd_report_4456.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4456\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4456\\pmd_report_4456.xml\n",
      "\n",
      "Skipping filtering for PR #4456 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4326 (6 files) ---\n",
      "Executing PMD for PR #4326: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4326 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4326\\pmd_report_4326.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4326\\pmd_report_4326.xml\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4252 (2 files) ---\n",
      "Executing PMD for PR #4252: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4252 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4252\\pmd_report_4252.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4252\\pmd_report_4252.xml\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4257 (5 files) ---\n",
      "Executing PMD for PR #4257: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4257 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4257\\pmd_report_4257.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4257\\pmd_report_4257.xml\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7801 (19 files) ---\n",
      "Executing PMD for PR #7801: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7801 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7801\\pmd_report_7801.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\typespec\\7801\\pmd_report_7801.xml\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4407 (0 files) ---\n",
      "Executing PMD for PR #4407: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4407 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4407\\pmd_report_4407.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4407\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4407\\pmd_report_4407.xml\n",
      "\n",
      "Skipping filtering for PR #4407 due to PMD failure.\n",
      "\n",
      "--- Processing PR: Azure/azure-sdk-for-java #45795 (5 files) ---\n",
      "Executing PMD for PR #45795: pmd.bat check -d ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45795 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45795\\pmd_report_45795.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45795\\pmd_report_45795.xml\n",
      "\n",
      "--- Processing PR: camunda/camunda #35602 (4 files) ---\n",
      "Executing PMD for PR #35602: pmd.bat check -d ./pr_analysis_staging\\camunda\\camunda\\35602 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\camunda\\camunda\\35602\\pmd_report_35602.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\camunda\\camunda\\35602\\pmd_report_35602.xml\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7481 (0 files) ---\n",
      "Executing PMD for PR #7481: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7481 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7481\\pmd_report_7481.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7481\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7481\\pmd_report_7481.xml\n",
      "\n",
      "Skipping filtering for PR #7481 due to PMD failure.\n",
      "\n",
      "--- Processing PR: EduMIPS64/edumips64 #1360 (11 files) ---\n",
      "Executing PMD for PR #1360: pmd.bat check -d ./pr_analysis_staging\\EduMIPS64\\edumips64\\1360 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\EduMIPS64\\edumips64\\1360\\pmd_report_1360.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\EduMIPS64\\edumips64\\1360\\pmd_report_1360.xml\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7602 (0 files) ---\n",
      "Executing PMD for PR #7602: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7602 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7602\\pmd_report_7602.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7602\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7602\\pmd_report_7602.xml\n",
      "\n",
      "Skipping filtering for PR #7602 due to PMD failure.\n",
      "\n",
      "--- Processing PR: apolloconfig/apollo #5438 (0 files) ---\n",
      "Executing PMD for PR #5438: pmd.bat check -d ./pr_analysis_staging\\apolloconfig\\apollo\\5438 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\apolloconfig\\apollo\\5438\\pmd_report_5438.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\apolloconfig\\apollo\\5438\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\apolloconfig\\apollo\\5438\\pmd_report_5438.xml\n",
      "\n",
      "Skipping filtering for PR #5438 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4287 (0 files) ---\n",
      "Executing PMD for PR #4287: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4287 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4287\\pmd_report_4287.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4287\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4287\\pmd_report_4287.xml\n",
      "\n",
      "Skipping filtering for PR #4287 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4288 (0 files) ---\n",
      "Executing PMD for PR #4288: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4288 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4288\\pmd_report_4288.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4288\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4288\\pmd_report_4288.xml\n",
      "\n",
      "Skipping filtering for PR #4288 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4289 (0 files) ---\n",
      "Executing PMD for PR #4289: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4289 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4289\\pmd_report_4289.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4289\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4289\\pmd_report_4289.xml\n",
      "\n",
      "Skipping filtering for PR #4289 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4290 (0 files) ---\n",
      "Executing PMD for PR #4290: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4290 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4290\\pmd_report_4290.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4290\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4290\\pmd_report_4290.xml\n",
      "\n",
      "Skipping filtering for PR #4290 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7458 (0 files) ---\n",
      "Executing PMD for PR #7458: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7458 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7458\\pmd_report_7458.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7458\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7458\\pmd_report_7458.xml\n",
      "\n",
      "Skipping filtering for PR #7458 due to PMD failure.\n",
      "\n",
      "--- Processing PR: Azure/azure-sdk-for-java #45808 (0 files) ---\n",
      "Executing PMD for PR #45808: pmd.bat check -d ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45808 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45808\\pmd_report_45808.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\Azure\\azure-sdk-for-java\\45808\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\Azure\\azure-sdk-for-java\\45808\\pmd_report_45808.xml\n",
      "\n",
      "Skipping filtering for PR #45808 due to PMD failure.\n",
      "\n",
      "--- Processing PR: objectionary/eo #4317 (7 files) ---\n",
      "Executing PMD for PR #4317: pmd.bat check -d ./pr_analysis_staging\\objectionary\\eo\\4317 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\objectionary\\eo\\4317\\pmd_report_4317.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\objectionary\\eo\\4317\\pmd_report_4317.xml\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4269 (3 files) ---\n",
      "Executing PMD for PR #4269: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4269 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4269\\pmd_report_4269.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4269\\pmd_report_4269.xml\n",
      "\n",
      "--- Processing PR: camunda/camunda #34932 (9 files) ---\n",
      "Executing PMD for PR #34932: pmd.bat check -d ./pr_analysis_staging\\camunda\\camunda\\34932 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\camunda\\camunda\\34932\\pmd_report_34932.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\camunda\\camunda\\34932\\pmd_report_34932.xml\n",
      "\n",
      "--- Processing PR: objectionary/eo #4280 (1 files) ---\n",
      "Executing PMD for PR #4280: pmd.bat check -d ./pr_analysis_staging\\objectionary\\eo\\4280 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\objectionary\\eo\\4280\\pmd_report_4280.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\objectionary\\eo\\4280\\pmd_report_4280.xml\n",
      "\n",
      "--- Processing PR: objectionary/eo #4282 (0 files) ---\n",
      "Executing PMD for PR #4282: pmd.bat check -d ./pr_analysis_staging\\objectionary\\eo\\4282 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\objectionary\\eo\\4282\\pmd_report_4282.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\objectionary\\eo\\4282\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\objectionary\\eo\\4282\\pmd_report_4282.xml\n",
      "\n",
      "Skipping filtering for PR #4282 due to PMD failure.\n",
      "\n",
      "--- Processing PR: 1c-syntax/bsl-language-server #3481 (2 files) ---\n",
      "Executing PMD for PR #3481: pmd.bat check -d ./pr_analysis_staging\\1c-syntax\\bsl-language-server\\3481 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\1c-syntax\\bsl-language-server\\3481\\pmd_report_3481.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\1c-syntax\\bsl-language-server\\3481\\pmd_report_3481.xml\n",
      "\n",
      "--- Processing PR: EduMIPS64/edumips64 #1361 (0 files) ---\n",
      "Executing PMD for PR #1361: pmd.bat check -d ./pr_analysis_staging\\EduMIPS64\\edumips64\\1361 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\EduMIPS64\\edumips64\\1361\\pmd_report_1361.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\EduMIPS64\\edumips64\\1361\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\EduMIPS64\\edumips64\\1361\\pmd_report_1361.xml\n",
      "\n",
      "Skipping filtering for PR #1361 due to PMD failure.\n",
      "\n",
      "--- Processing PR: camunda/camunda #34576 (9 files) ---\n",
      "Executing PMD for PR #34576: pmd.bat check -d ./pr_analysis_staging\\camunda\\camunda\\34576 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\camunda\\camunda\\34576\\pmd_report_34576.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\camunda\\camunda\\34576\\pmd_report_34576.xml\n",
      "\n",
      "--- Processing PR: wgzhao/Addax #1321 (0 files) ---\n",
      "Executing PMD for PR #1321: pmd.bat check -d ./pr_analysis_staging\\wgzhao\\Addax\\1321 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\wgzhao\\Addax\\1321\\pmd_report_1321.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\wgzhao\\Addax\\1321\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\wgzhao\\Addax\\1321\\pmd_report_1321.xml\n",
      "\n",
      "Skipping filtering for PR #1321 due to PMD failure.\n",
      "\n",
      "--- Processing PR: OWASP/wrongsecrets #2120 (0 files) ---\n",
      "Executing PMD for PR #2120: pmd.bat check -d ./pr_analysis_staging\\OWASP\\wrongsecrets\\2120 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\OWASP\\wrongsecrets\\2120\\pmd_report_2120.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\OWASP\\wrongsecrets\\2120\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\OWASP\\wrongsecrets\\2120\\pmd_report_2120.xml\n",
      "\n",
      "Skipping filtering for PR #2120 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4262 (0 files) ---\n",
      "Executing PMD for PR #4262: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4262 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4262\\pmd_report_4262.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4262\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4262\\pmd_report_4262.xml\n",
      "\n",
      "Skipping filtering for PR #4262 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/ApplicationInsights-Java #4377 (1 files) ---\n",
      "Executing PMD for PR #4377: pmd.bat check -d ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4377 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4377\\pmd_report_4377.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\microsoft\\ApplicationInsights-Java\\4377\\pmd_report_4377.xml\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4471 (0 files) ---\n",
      "Executing PMD for PR #4471: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4471 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4471\\pmd_report_4471.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4471\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4471\\pmd_report_4471.xml\n",
      "\n",
      "Skipping filtering for PR #4471 due to PMD failure.\n",
      "\n",
      "--- Processing PR: microsoft/typespec #7760 (0 files) ---\n",
      "Executing PMD for PR #7760: pmd.bat check -d ./pr_analysis_staging\\microsoft\\typespec\\7760 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\microsoft\\typespec\\7760\\pmd_report_7760.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\microsoft\\typespec\\7760\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\microsoft\\typespec\\7760\\pmd_report_7760.xml\n",
      "\n",
      "Skipping filtering for PR #7760 due to PMD failure.\n",
      "\n",
      "--- Processing PR: valkey-io/valkey-glide #4481 (0 files) ---\n",
      "Executing PMD for PR #4481: pmd.bat check -d ./pr_analysis_staging\\valkey-io\\valkey-glide\\4481 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\valkey-io\\valkey-glide\\4481\\pmd_report_4481.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4481\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\valkey-io\\valkey-glide\\4481\\pmd_report_4481.xml\n",
      "\n",
      "Skipping filtering for PR #4481 due to PMD failure.\n",
      "\n",
      "--- Processing PR: OWASP/wrongsecrets #2115 (0 files) ---\n",
      "Executing PMD for PR #2115: pmd.bat check -d ./pr_analysis_staging\\OWASP\\wrongsecrets\\2115 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\OWASP\\wrongsecrets\\2115\\pmd_report_2115.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\OWASP\\wrongsecrets\\2115\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\OWASP\\wrongsecrets\\2115\\pmd_report_2115.xml\n",
      "\n",
      "Skipping filtering for PR #2115 due to PMD failure.\n",
      "\n",
      "--- Processing PR: camunda/camunda #35374 (30 files) ---\n",
      "Executing PMD for PR #35374: pmd.bat check -d ./pr_analysis_staging\\camunda\\camunda\\35374 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\camunda\\camunda\\35374\\pmd_report_35374.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\camunda\\camunda\\35374\\pmd_report_35374.xml\n",
      "\n",
      "--- Processing PR: Azure/azure-sdk-for-java #45595 (0 files) ---\n",
      "Executing PMD for PR #45595: pmd.bat check -d ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45595 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\Azure\\azure-sdk-for-java\\45595\\pmd_report_45595.xml\n",
      "PMD command failed (code 1). Error:\n",
      "[ERROR] No such file .\\pr_analysis_staging\\Azure\\azure-sdk-for-java\\45595\n",
      "[ERROR] Could not initialize analysis: java.nio.file.NoSuchFileException: .\\pr_analysis_staging\\Azure\\azure-sdk-for-java\\45595\\pmd_report_45595.xml\n",
      "\n",
      "Skipping filtering for PR #45595 due to PMD failure.\n",
      "\n",
      "--- Processing PR: camunda/camunda #35347 (3 files) ---\n",
      "Executing PMD for PR #35347: pmd.bat check -d ./pr_analysis_staging\\camunda\\camunda\\35347 -R D:/Program Files/PMD/pmd-bin-7.18.0/rulesets/java/quickstart.xml -f xml -r ./pr_analysis_staging\\camunda\\camunda\\35347\\pmd_report_35347.xml\n",
      "PMD analysis completed. Report saved to: ./pr_analysis_staging\\camunda\\camunda\\35347\\pmd_report_35347.xml\n"
     ]
    }
   ],
   "source": [
    "all_pmd_metrics = []\n",
    "for pr_data in pr_code_metrics_filtered_accepted:\n",
    "    owner = pr_data['owner']\n",
    "    repo = pr_data['repo']\n",
    "    pr_number = pr_data['pr_number']\n",
    "    files_to_analyze = pr_data['files_to_analyze'] \n",
    "    \n",
    "    # Create a local staging directory structure. Prevents file path clashes and organizes your PMD reports\n",
    "    base_dir = \"./pr_analysis_staging\"\n",
    "    local_staging_dir = os.path.join(base_dir, owner, repo, str(pr_number))\n",
    "    \n",
    "    print(f\"\\n--- Processing PR: {owner}/{repo} #{pr_number} ({len(files_to_analyze)} files) ---\")\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. Run PMD Analysis on the downloaded files\n",
    "    # ------------------------------------------------------------------\n",
    "    pmd_report_path = run_pmd_for_pr(owner, repo, pr_number)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. Next step: Parse the XML report and filter by the patch/diff data\n",
    "    # ------------------------------------------------------------------\n",
    "    if pmd_report_path:\n",
    "        # Store the report path in your PR data dictionary for later parsing\n",
    "        pr_data['pmd_report_path'] = pmd_report_path\n",
    "        rule_counts_dict = parse_pmd_report_to_counts(pmd_report_path, pr_number)\n",
    "        \n",
    "        if rule_counts_dict:\n",
    "            # Add the dictionary to your collection list\n",
    "            all_pmd_metrics.append(rule_counts_dict)\n",
    "            \n",
    "            # Optionally, update the original PR data structure\n",
    "            pr_data['pmd_violations'] = rule_counts_dict\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(f\"Skipping filtering for PR #{pr_number} due to PMD failure.\")\n",
    "        \n",
    "# ============================================================\n",
    "# Final Step: Convert the list of dictionaries to a single DataFrame\n",
    "# ============================================================\n",
    "if all_pmd_metrics:\n",
    "    # Use fillna(0) to ensure PRs that didn't violate a rule get a count of 0\n",
    "    df_pmd_counts = pd.DataFrame(all_pmd_metrics).fillna(0)\n",
    "    \n",
    "    # 2. Reorder the columns this way since there are too many weird columns name\n",
    "    # Get all column names\n",
    "    all_cols = df_pmd_counts.columns.tolist()\n",
    "    \n",
    "    # Filter out the 'pr_number' column \n",
    "    rule_id_cols = [col for col in all_cols if col != 'pr_number']\n",
    "    \n",
    "    # Define the new column order: ['pr_number', then all the rest]\n",
    "    new_col_order = ['pr_number'] + sorted(rule_id_cols)\n",
    "    \n",
    "    # Apply the new order to the DataFrame\n",
    "    df_pmd_counts = df_pmd_counts[new_col_order]\n",
    "    \n",
    "    # Save the final PMD features to a CSV\n",
    "    df_pmd_counts.to_csv(\"all_pr_pmd_features_accepted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15294ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pmd_metrics = []\n",
    "for pr_data in pr_code_metrics_filtered_rejected:\n",
    "    owner = pr_data['owner']\n",
    "    repo = pr_data['repo']\n",
    "    pr_number = pr_data['pr_number']\n",
    "    files_to_analyze = pr_data['files_to_analyze'] \n",
    "    \n",
    "    # Create a local staging directory structure. Prevents file path clashes and organizes your PMD reports\n",
    "    base_dir = \"./pr_analysis_staging\"\n",
    "    local_staging_dir = os.path.join(base_dir, owner, repo, str(pr_number))\n",
    "    \n",
    "    print(f\"\\n--- Processing PR: {owner}/{repo} #{pr_number} ({len(files_to_analyze)} files) ---\")\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. Run PMD Analysis on the downloaded files\n",
    "    # ------------------------------------------------------------------\n",
    "    pmd_report_path = run_pmd_for_pr(owner, repo, pr_number)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. Next step: Parse the XML report and filter by the patch/diff data\n",
    "    # ------------------------------------------------------------------\n",
    "    if pmd_report_path:\n",
    "        # Store the report path in your PR data dictionary for later parsing\n",
    "        pr_data['pmd_report_path'] = pmd_report_path\n",
    "        rule_counts_dict = parse_pmd_report_to_counts(pmd_report_path, pr_number)\n",
    "        \n",
    "        if rule_counts_dict:\n",
    "            # Add the dictionary to your collection list\n",
    "            all_pmd_metrics.append(rule_counts_dict)\n",
    "            \n",
    "            # Optionally, update the original PR data structure\n",
    "            pr_data['pmd_violations'] = rule_counts_dict\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(f\"Skipping filtering for PR #{pr_number} due to PMD failure.\")\n",
    "        \n",
    "# ============================================================\n",
    "# Final Step: Convert the list of dictionaries to a single DataFrame\n",
    "# ============================================================\n",
    "if all_pmd_metrics:\n",
    "    # Use fillna(0) to ensure PRs that didn't violate a rule get a count of 0\n",
    "    df_pmd_counts = pd.DataFrame(all_pmd_metrics).fillna(0)\n",
    "    \n",
    "    # 2. Reorder the columns this way since there are too many weird columns name\n",
    "    # Get all column names\n",
    "    all_cols = df_pmd_counts.columns.tolist()\n",
    "    \n",
    "    # Filter out the 'pr_number' column \n",
    "    rule_id_cols = [col for col in all_cols if col != 'pr_number']\n",
    "    \n",
    "    # Define the new column order: ['pr_number', then all the rest]\n",
    "    new_col_order = ['pr_number'] + sorted(rule_id_cols)\n",
    "    \n",
    "    # Apply the new order to the DataFrame\n",
    "    df_pmd_counts = df_pmd_counts[new_col_order]\n",
    "    \n",
    "    # Save the final PMD features to a CSV\n",
    "    df_pmd_counts.to_csv(\"all_pr_pmd_features_rejected.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
