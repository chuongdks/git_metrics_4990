{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149048ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional\n",
    "import readability\n",
    "import syntok.segmenter as segmenter\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./api_key.env\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da340c98",
   "metadata": {},
   "source": [
    "# Import the Hao-Li AIDev datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2df0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repositories\n",
    "repo_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/repository.parquet\")\n",
    "\n",
    "# Pull Request\n",
    "pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n",
    "\n",
    "# Related issues\n",
    "related_issue_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/related_issue.parquet\")\n",
    "issue_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/issue.parquet\", columns=['id', 'number', 'body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df6a28",
   "metadata": {},
   "source": [
    "# 1. Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89954997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_number</th>\n",
       "      <th>body_x</th>\n",
       "      <th>pr_id</th>\n",
       "      <th>issue_id</th>\n",
       "      <th>pr_number</th>\n",
       "      <th>title</th>\n",
       "      <th>body_y</th>\n",
       "      <th>agent</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>merged_at</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23190</td>\n",
       "      <td>### Search before asking\\n\\n- [X] I searched i...</td>\n",
       "      <td>3250080019</td>\n",
       "      <td>2.471504e+09</td>\n",
       "      <td>24542</td>\n",
       "      <td>[fix][broker]Fix thread safety issues in Bucke...</td>\n",
       "      <td>### Motivation\\r\\n\\r\\nFixes #23190\\r\\n\\r\\nBuck...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>10327630</td>\n",
       "      <td>Apurva007</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-21T21:21:39Z</td>\n",
       "      <td>2025-07-22T06:17:01Z</td>\n",
       "      <td>2025-07-22T06:17:01Z</td>\n",
       "      <td>62117812</td>\n",
       "      <td>https://api.github.com/repos/apache/pulsar</td>\n",
       "      <td>https://github.com/apache/pulsar/pull/24542</td>\n",
       "      <td>apache/pulsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24138</td>\n",
       "      <td>### Search before asking\\n\\n- [x] I searched i...</td>\n",
       "      <td>2959025892</td>\n",
       "      <td>2.955889e+09</td>\n",
       "      <td>24145</td>\n",
       "      <td>[fix][cli] Enhance split-bundle command to acc...</td>\n",
       "      <td>- Modified pulsar-admin CLI to handle both...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>201149937</td>\n",
       "      <td>alexander-nailed-it</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-03-30T18:27:22Z</td>\n",
       "      <td>2025-04-18T18:12:35Z</td>\n",
       "      <td>None</td>\n",
       "      <td>62117812</td>\n",
       "      <td>https://api.github.com/repos/apache/pulsar</td>\n",
       "      <td>https://github.com/apache/pulsar/pull/24145</td>\n",
       "      <td>apache/pulsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3390</td>\n",
       "      <td>Было бы не плохо, возможно опционально, по умо...</td>\n",
       "      <td>3114848770</td>\n",
       "      <td>2.799329e+09</td>\n",
       "      <td>3481</td>\n",
       "      <td>Add excludeTrailingComments option to LineLeng...</td>\n",
       "      <td>This PR adds a new configuration parameter `ex...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-03T17:34:41Z</td>\n",
       "      <td>2025-06-03T20:24:48Z</td>\n",
       "      <td>2025-06-03T20:24:48Z</td>\n",
       "      <td>163654595</td>\n",
       "      <td>https://api.github.com/repos/1c-syntax/bsl-lan...</td>\n",
       "      <td>https://github.com/1c-syntax/bsl-language-serv...</td>\n",
       "      <td>1c-syntax/bsl-language-server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3482</td>\n",
       "      <td>Публикация артефактов в OOSRH больше не доступ...</td>\n",
       "      <td>3116095750</td>\n",
       "      <td>3.116096e+09</td>\n",
       "      <td>3483</td>\n",
       "      <td>Migrate from legacy OSSRH to Central Portal fo...</td>\n",
       "      <td>This PR migrates the Maven/Sonatype publishing...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-06-04T02:39:37Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>163654595</td>\n",
       "      <td>https://api.github.com/repos/1c-syntax/bsl-lan...</td>\n",
       "      <td>https://github.com/1c-syntax/bsl-language-serv...</td>\n",
       "      <td>1c-syntax/bsl-language-server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3485</td>\n",
       "      <td>Sentry Issue: [BSL-LANGUAGE-SERVER-DW](https:/...</td>\n",
       "      <td>3145625420</td>\n",
       "      <td>3.145622e+09</td>\n",
       "      <td>3486</td>\n",
       "      <td>Fix ClassCastException in MagicNumberDiagnosti...</td>\n",
       "      <td>The `MagicNumberDiagnostic.configure()` method...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-06-14T07:07:30Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>163654595</td>\n",
       "      <td>https://api.github.com/repos/1c-syntax/bsl-lan...</td>\n",
       "      <td>https://github.com/1c-syntax/bsl-language-serv...</td>\n",
       "      <td>1c-syntax/bsl-language-server</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   issue_number                                             body_x  \\\n",
       "0         23190  ### Search before asking\\n\\n- [X] I searched i...   \n",
       "1         24138  ### Search before asking\\n\\n- [x] I searched i...   \n",
       "2          3390  Было бы не плохо, возможно опционально, по умо...   \n",
       "3          3482  Публикация артефактов в OOSRH больше не доступ...   \n",
       "4          3485  Sentry Issue: [BSL-LANGUAGE-SERVER-DW](https:/...   \n",
       "\n",
       "        pr_id      issue_id  pr_number  \\\n",
       "0  3250080019  2.471504e+09      24542   \n",
       "1  2959025892  2.955889e+09      24145   \n",
       "2  3114848770  2.799329e+09       3481   \n",
       "3  3116095750  3.116096e+09       3483   \n",
       "4  3145625420  3.145622e+09       3486   \n",
       "\n",
       "                                               title  \\\n",
       "0  [fix][broker]Fix thread safety issues in Bucke...   \n",
       "1  [fix][cli] Enhance split-bundle command to acc...   \n",
       "2  Add excludeTrailingComments option to LineLeng...   \n",
       "3  Migrate from legacy OSSRH to Central Portal fo...   \n",
       "4  Fix ClassCastException in MagicNumberDiagnosti...   \n",
       "\n",
       "                                              body_y        agent    user_id  \\\n",
       "0  ### Motivation\\r\\n\\r\\nFixes #23190\\r\\n\\r\\nBuck...  Claude_Code   10327630   \n",
       "1      - Modified pulsar-admin CLI to handle both...  Claude_Code  201149937   \n",
       "2  This PR adds a new configuration parameter `ex...      Copilot  198982749   \n",
       "3  This PR migrates the Maven/Sonatype publishing...      Copilot  198982749   \n",
       "4  The `MagicNumberDiagnostic.configure()` method...      Copilot  198982749   \n",
       "\n",
       "                  user   state            created_at             closed_at  \\\n",
       "0            Apurva007  closed  2025-07-21T21:21:39Z  2025-07-22T06:17:01Z   \n",
       "1  alexander-nailed-it  closed  2025-03-30T18:27:22Z  2025-04-18T18:12:35Z   \n",
       "2              Copilot  closed  2025-06-03T17:34:41Z  2025-06-03T20:24:48Z   \n",
       "3              Copilot    open  2025-06-04T02:39:37Z                  None   \n",
       "4              Copilot    open  2025-06-14T07:07:30Z                  None   \n",
       "\n",
       "              merged_at    repo_id  \\\n",
       "0  2025-07-22T06:17:01Z   62117812   \n",
       "1                  None   62117812   \n",
       "2  2025-06-03T20:24:48Z  163654595   \n",
       "3                  None  163654595   \n",
       "4                  None  163654595   \n",
       "\n",
       "                                            repo_url  \\\n",
       "0         https://api.github.com/repos/apache/pulsar   \n",
       "1         https://api.github.com/repos/apache/pulsar   \n",
       "2  https://api.github.com/repos/1c-syntax/bsl-lan...   \n",
       "3  https://api.github.com/repos/1c-syntax/bsl-lan...   \n",
       "4  https://api.github.com/repos/1c-syntax/bsl-lan...   \n",
       "\n",
       "                                            html_url  \\\n",
       "0        https://github.com/apache/pulsar/pull/24542   \n",
       "1        https://github.com/apache/pulsar/pull/24145   \n",
       "2  https://github.com/1c-syntax/bsl-language-serv...   \n",
       "3  https://github.com/1c-syntax/bsl-language-serv...   \n",
       "4  https://github.com/1c-syntax/bsl-language-serv...   \n",
       "\n",
       "                       full_name  \n",
       "0                  apache/pulsar  \n",
       "1                  apache/pulsar  \n",
       "2  1c-syntax/bsl-language-server  \n",
       "3  1c-syntax/bsl-language-server  \n",
       "4  1c-syntax/bsl-language-server  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter the repository data for 'Java' language\n",
    "java_repo_df = repo_df[repo_df['language'] == 'Java'].copy()\n",
    "java_repo_select_df = java_repo_df[['id', 'full_name']]\n",
    "\n",
    "# Join Repo and PR table based on repo id\n",
    "merged_pr_df = pr_df.merge(\n",
    "    java_repo_select_df,\n",
    "    left_on='repo_id',\n",
    "    right_on='id',\n",
    "    how='inner'\n",
    ")\n",
    "print(len(merged_pr_df))\n",
    "# clean up extra attribute\n",
    "merged_pr_df = merged_pr_df.drop(columns=['id_y'])\n",
    "merged_pr_df = merged_pr_df.rename(columns={'id_x':'id'})\n",
    "\n",
    "# Join the merged table with pr_commit\n",
    "merged_pr_df = related_issue_df.merge(\n",
    "    merged_pr_df,\n",
    "    left_on='pr_id',\n",
    "    right_on='id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# clean up extra attribute\n",
    "merged_pr_df = merged_pr_df.drop(columns=['id','source'])\n",
    "\n",
    "\n",
    "# Join the merged table with pr_commit\n",
    "merged_pr_df = issue_df.merge(\n",
    "    merged_pr_df,\n",
    "    left_on='id',\n",
    "    right_on='issue_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# clean up extra attribute\n",
    "merged_pr_df = merged_pr_df.drop(columns=['id'])\n",
    "rename_map = {\n",
    "    'number_x':             'issue_number',\n",
    "    'number_y':           'pr_number',\n",
    "}\n",
    "merged_pr_df = merged_pr_df.rename(columns=rename_map)\n",
    "display(merged_pr_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fc16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter PRs that were rejected (not merged) and create a new attribute\n",
    "accepted_prs = merged_pr_df[merged_pr_df['merged_at'].notnull()]\n",
    "rejected_prs = merged_pr_df[merged_pr_df['merged_at'].isnull()]\n",
    "\n",
    "# Prepare for Merge: Rename the key column\n",
    "accepted_prs = accepted_prs[['full_name', 'issue_number', 'pr_number']]\n",
    "rejected_prs = rejected_prs[['full_name', 'issue_number', 'pr_number']]\n",
    "\n",
    "# print to csv for checking\n",
    "accepted_prs.to_csv(\"accepted_PR.csv\", index=False)\n",
    "rejected_prs.to_csv(\"rejected_PR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b13051",
   "metadata": {},
   "source": [
    "## 1.2. Split the full_name of repo into owner and repo name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14daec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apache', 'pulsar', 23190, 24542), ('1c-syntax', 'bsl-language-server', 3390, 3481), ('Azure', 'azure-sdk-for-java', 42765, 45797), ('Azure', 'azure-sdk-for-java', 45594, 45595), ('Azure', 'azure-sdk-for-java', 45762, 45795)]\n",
      "[('apache', 'pulsar', 24138, 24145), ('1c-syntax', 'bsl-language-server', 3482, 3483), ('1c-syntax', 'bsl-language-server', 3485, 3486), ('AutoMQ', 'automq', 2650, 2652), ('Azure-Samples', 'azure-search-openai-demo-java', 54, 111)]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Split the name and put it in a List of Dict (not needed but ehh accidentally made the method like that)\n",
    "# ============================================================\n",
    "def process_repositories(pr_df):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame by status, splits the full_name, and creates a \n",
    "    list of (owner, repo) tuples for processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Split the 'full_name' column into 'owner' and 'repo' columns\n",
    "    split_df = pr_df['full_name'].str.split('/', n=1, expand=True)\n",
    "    split_df.columns = ['owner', 'repo']\n",
    "    \n",
    "    # 2. Combine the split columns and the 'number' column into a list of tuples\n",
    "    # We use axis=1 to apply the tuple creation row-wise across the three columns\n",
    "    combined_df = pd.concat([split_df, pr_df['issue_number'], pr_df['pr_number']],axis=1) # use axis=1 to apply the tuple creation row-wise across the three columns\n",
    "    \n",
    "    #\n",
    "    repositories = combined_df.apply(tuple, axis=1).tolist()\n",
    "    print(repositories[:5])\n",
    "    \n",
    "    return repositories\n",
    "\n",
    "\n",
    "ACCEPTED_PULL_REQUEST = process_repositories(accepted_prs)\n",
    "REJECTED_PULL_REQUEST = process_repositories(rejected_prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5482fa",
   "metadata": {},
   "source": [
    "# 2. Helper code block to limit the API rate request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c42486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "def safe_request(method, url, headers=None, params=None, timeout=10, sleep_between=0.4):\n",
    "    \"\"\"\n",
    "    A rate-limit-safe GitHub request wrapper that handles:\n",
    "    - Primary rate limits (5000/hour)\n",
    "    - Secondary abuse limits (burst protection)\n",
    "    - GET and HEAD requests\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        response = requests.request(method, url, headers=headers, params=params, timeout=timeout)\n",
    "\n",
    "        # Primary rate limit\n",
    "        remaining = int(response.headers.get(\"X-RateLimit-Remaining\", 1))\n",
    "        reset_ts = int(response.headers.get(\"X-RateLimit-Reset\", time.time()))\n",
    "\n",
    "        if remaining == 0:\n",
    "            wait = max(reset_ts - int(time.time()), 10)\n",
    "            print(f\"[Primary Limit] Waiting {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "            continue\n",
    "\n",
    "        # Secondary rate limit (abuse detection)\n",
    "        if response.status_code == 403:\n",
    "            print(\"[Secondary Limit] Hit GitHub abuse limit. Backing off 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        # Success or other errors handled normally\n",
    "        if not response.ok:\n",
    "            response.raise_for_status()\n",
    "\n",
    "        # Small delay prevents triggering secondary limit\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf896a",
   "metadata": {},
   "source": [
    "# 3. Git API to extract metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data retrieval... (may take a moment due to multiple API calls)\n",
      "[Primary Limit] Waiting 3554 seconds...\n",
      "[Primary Limit] Waiting 3554 seconds...\n",
      "[Primary Limit] Waiting 3553 seconds...\n",
      "[Primary Limit] Waiting 3553 seconds...\n",
      "[Primary Limit] Waiting 3550 seconds...\n",
      "[Primary Limit] Waiting 3552 seconds...\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# Helper: Function for Preprocessing and Scoring\n",
    "# ----------------------------------------------------\n",
    "def get_readability_score(text: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Tokenizes text using syntok and returns the Flesch Reading Ease score.\n",
    "    Returns None if the text is empty or analysis fails.\n",
    "    Based on: https://pypi.org/project/readability/\n",
    "    \"\"\"\n",
    "    if not text or text == \"No body content provided.\":\n",
    "        return None\n",
    "    \n",
    "    # 1. Use syntok to tokenize and segment the text\n",
    "    # This complex join statement transforms the raw string into the required format:\n",
    "    # 'word1 word2 .\\nword3 word4 .\\n\\nnew_paragraph_word1 .'\n",
    "    try:\n",
    "        tokenized = '\\n\\n'.join(\n",
    "            '\\n'.join(' '.join(token.value for token in sentence) \n",
    "                      for sentence in paragraph)\n",
    "            for paragraph in segmenter.analyze(text)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during syntok analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Calculate the readability scores\n",
    "    try:\n",
    "        # Check if the tokenized text is not empty before scoring\n",
    "        if not tokenized.strip():\n",
    "            return None\n",
    "            \n",
    "        results = readability.getmeasures(tokenized, lang='en')\n",
    "        \n",
    "        # We will return the Flesch Reading Ease score as an example\n",
    "        return results['readability grades']['FleschReadingEase']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating readability score: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# Helper 1: Fetch Metrics for Issue\n",
    "# ============================================================\n",
    "def fetch_single_issue(owner: str, repo: str, issue_number: int, github_token: Optional[str]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetches the title, body, and labels for a single issue number.\n",
    "    Returns None if the issue is a PR, deleted, or if an error occurs.\n",
    "    \"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo}/issues/{issue_number}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github.v3+json\",\n",
    "    }\n",
    "    if github_token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {github_token}\"\n",
    "\n",
    "    try:\n",
    "        response = safe_request(\"GET\", api_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        issue_data = response.json()\n",
    "\n",
    "        # Check if the object is actually a Pull Request (PR)\n",
    "        if 'pull_request' in issue_data:\n",
    "            print(f\"   [SKIP] #{issue_number} is a Pull Request, skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Extract the body fields for readability\n",
    "        issue_body = issue_data.get('body') or \"No body content provided.\"\n",
    "\n",
    "        # Calculate Readability Score\n",
    "        flesch_score = get_readability_score(issue_body)\n",
    "        \n",
    "        # Extract the required fields\n",
    "        return {\n",
    "            #\"type\": \"issue\",\n",
    "            \"issue_number\": issue_number,\n",
    "            \"issue_title\": issue_data.get('title'),\n",
    "            \"issue_body\": issue_body,\n",
    "            #\"issue_labels\": [label['name'] for label in issue_data.get('labels', [])],\n",
    "            #\"isue_url\": issue_data.get('html_url'),\n",
    "            \"issue_readability\": flesch_score\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if response.status_code == 404:\n",
    "            print(f\"   [FAIL] #{issue_number} not found (Error 404).\")\n",
    "        else:\n",
    "            print(f\"   [FAIL] HTTP Error for #{issue_number}: {e}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   [FAIL] Connection Error for #{issue_number}: {e}\")\n",
    "        return None\n",
    "    \n",
    "# ----------------------------------------------------\n",
    "# Helper 2: Fetch Metrics for PR\n",
    "# ----------------------------------------------------\n",
    "def fetch_single_pr(owner: str, repo: str, issue_number: int, pr_number: int, github_token: Optional[str]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetches the title, body, labels, and readability score for a single Pull Request number.\n",
    "    Returns None if the PR is deleted or if an error occurs.\n",
    "    \"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github.v3+json\",\n",
    "    }\n",
    "    if github_token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {github_token}\"\n",
    "\n",
    "    try:\n",
    "        response = safe_request(\"GET\", api_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        pr_data = response.json()\n",
    "        \n",
    "        pr_body = pr_data.get('body') or \"No body content provided.\"\n",
    "\n",
    "        # Calculate Readability Score\n",
    "        flesch_score = get_readability_score(pr_body)\n",
    "        \n",
    "        issues_readability_metrics = fetch_single_issue(owner, repo, issue_number, github_token)\n",
    "        \n",
    "        # Extract the required fields\n",
    "        return {\n",
    "            #\"type\": \"pull_request\",\n",
    "            \"Repo\": f\"{owner}/{repo}\",\n",
    "            \"PR_Number\": pr_number,\n",
    "            \"pr_title\": pr_data.get('title'),\n",
    "            \"pr_body\": pr_body,\n",
    "            #\"pr_labels\": [label['name'] for label in pr_data.get('labels', [])],\n",
    "            #\"pr_url\": pr_data.get('html_url'),\n",
    "            \"pr_readability\": flesch_score,\n",
    "            **issues_readability_metrics\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if response.status_code == 404:\n",
    "            print(f\"   [FAIL] PR #{pr_number} not found (Error 404).\")\n",
    "        else:\n",
    "            print(f\"   [FAIL] HTTP Error for PR #{pr_number}: {e}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   [FAIL] Connection Error for PR #{pr_number}: {e}\")\n",
    "        return None\n",
    "    \n",
    "# ============================================================\n",
    "# Main Helper: Fetch the main metric functions \n",
    "# ============================================================\n",
    "def fetch_metrics(repo_list, token):\n",
    "    results = []\n",
    "    # limit the number of repositories processed here for testing REPOSITORIES[:10]:\n",
    "    for owner, repo, issue_number, pr_number in repo_list: # Apply the test limit here\n",
    "        metrics = fetch_single_pr(owner, repo, issue_number, pr_number, token)\n",
    "        if metrics:\n",
    "            results.append(metrics)\n",
    "    \n",
    "    # Create the Metric DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROGRAM\n",
    "# ============================================================\n",
    "print(\"\\nStarting data retrieval... (may take a moment due to multiple API calls)\")\n",
    "pr_readability_df_accept = fetch_metrics(ACCEPTED_PULL_REQUEST, GITHUB_TOKEN)\n",
    "pr_readability_df_reject = fetch_metrics(REJECTED_PULL_REQUEST, GITHUB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7355a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>pr_number</th>\n",
       "      <th>pr_title</th>\n",
       "      <th>pr_body</th>\n",
       "      <th>pr_readability</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>issue_body</th>\n",
       "      <th>issue_readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue</td>\n",
       "      <td>24542</td>\n",
       "      <td>[fix][broker]Fix thread safety issues in Bucke...</td>\n",
       "      <td>### Motivation\\r\\n\\r\\nFixes #23190\\r\\n\\r\\nBuck...</td>\n",
       "      <td>20.666222</td>\n",
       "      <td>23190</td>\n",
       "      <td>[Bug] BucketDelayedDeliveryTracker.containsMes...</td>\n",
       "      <td>### Search before asking\\n\\n- [X] I searched i...</td>\n",
       "      <td>37.379912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>issue</td>\n",
       "      <td>3481</td>\n",
       "      <td>Add excludeTrailingComments option to LineLeng...</td>\n",
       "      <td>This PR adds a new configuration parameter `ex...</td>\n",
       "      <td>8.134711</td>\n",
       "      <td>3390</td>\n",
       "      <td>Не учитывать инлайн комментарии в длине строки</td>\n",
       "      <td>Было бы не плохо, возможно опционально, по умо...</td>\n",
       "      <td>198.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue</td>\n",
       "      <td>45797</td>\n",
       "      <td>Refactor SDK test dependencies from TestBase t...</td>\n",
       "      <td>This PR completes the migration of SDK test cl...</td>\n",
       "      <td>43.317290</td>\n",
       "      <td>42765</td>\n",
       "      <td>Refactor SDKs dependency on TestBase</td>\n",
       "      <td>Update all files taking a dependency on TestBa...</td>\n",
       "      <td>69.141364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue</td>\n",
       "      <td>45595</td>\n",
       "      <td>Remove unnecessary Maven plugins from azure-op...</td>\n",
       "      <td>This PR removes 4 unnecessary Maven plugins fr...</td>\n",
       "      <td>27.222647</td>\n",
       "      <td>45594</td>\n",
       "      <td>Copilot: Remove Unused OpenRewrite plugins</td>\n",
       "      <td>This task is a prompt for GitHub Copilot to co...</td>\n",
       "      <td>49.202272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issue</td>\n",
       "      <td>45795</td>\n",
       "      <td>Deprecate SharedTokenCacheCredential and remov...</td>\n",
       "      <td>This PR deprecates the `SharedTokenCacheCreden...</td>\n",
       "      <td>9.421703</td>\n",
       "      <td>45762</td>\n",
       "      <td>Deprecate SharedTokenCacheCredential</td>\n",
       "      <td>**Ask**: \\n- [ ] Deprecate `SharedTokenCacheCr...</td>\n",
       "      <td>24.581275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  pr_number                                           pr_title  \\\n",
       "0  issue      24542  [fix][broker]Fix thread safety issues in Bucke...   \n",
       "1  issue       3481  Add excludeTrailingComments option to LineLeng...   \n",
       "2  issue      45797  Refactor SDK test dependencies from TestBase t...   \n",
       "3  issue      45595  Remove unnecessary Maven plugins from azure-op...   \n",
       "4  issue      45795  Deprecate SharedTokenCacheCredential and remov...   \n",
       "\n",
       "                                             pr_body  pr_readability  \\\n",
       "0  ### Motivation\\r\\n\\r\\nFixes #23190\\r\\n\\r\\nBuck...       20.666222   \n",
       "1  This PR adds a new configuration parameter `ex...        8.134711   \n",
       "2  This PR completes the migration of SDK test cl...       43.317290   \n",
       "3  This PR removes 4 unnecessary Maven plugins fr...       27.222647   \n",
       "4  This PR deprecates the `SharedTokenCacheCreden...        9.421703   \n",
       "\n",
       "   issue_number                                        issue_title  \\\n",
       "0         23190  [Bug] BucketDelayedDeliveryTracker.containsMes...   \n",
       "1          3390     Не учитывать инлайн комментарии в длине строки   \n",
       "2         42765               Refactor SDKs dependency on TestBase   \n",
       "3         45594         Copilot: Remove Unused OpenRewrite plugins   \n",
       "4         45762               Deprecate SharedTokenCacheCredential   \n",
       "\n",
       "                                          issue_body  issue_readability  \n",
       "0  ### Search before asking\\n\\n- [X] I searched i...          37.379912  \n",
       "1  Было бы не плохо, возможно опционально, по умо...         198.715000  \n",
       "2  Update all files taking a dependency on TestBa...          69.141364  \n",
       "3  This task is a prompt for GitHub Copilot to co...          49.202272  \n",
       "4  **Ask**: \\n- [ ] Deprecate `SharedTokenCacheCr...          24.581275  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pr_readability_df_accept.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e07b7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Accepted Repositories ---\n",
      "\n",
      "Accepted Repository Metrics DataFrame Created:\n",
      "Total rows in Accepted DataFrame: 69\n",
      "\n",
      "--- Processing Rejected Repositories ---\n",
      "\n",
      "Rejected Repository Metrics DataFrame Created:\n",
      "Total rows in Rejected DataFrame: 113\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Finalize the dataframe, adding stars and forks\n",
    "# ============================================================\n",
    "def finalize_dataframe(metrics_df, output_filename):\n",
    "    \"\"\"\n",
    "    Applies the merging, cleaning, renaming, and reordering steps \n",
    "    to a single metrics DataFrame.\n",
    "    \"\"\"\n",
    "    #\n",
    "    final_df = metrics_df.fillna(0)\n",
    "\n",
    "    # 4. Save the file (using CSV as per your original request)\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROGRAM - Separate Processing\n",
    "# ============================================================\n",
    "\n",
    "# --- Processing Accepted Repositories ---\n",
    "print(\"\\n--- Processing Accepted Repositories ---\")\n",
    "final_df_accept = finalize_dataframe(\n",
    "    pr_readability_df_accept, \n",
    "    \"issue_pr_readability_accepted.csv\" # Save to a separate file\n",
    ")\n",
    "\n",
    "print(\"\\nAccepted Repository Metrics DataFrame Created:\")\n",
    "print(f\"Total rows in Accepted DataFrame: {len(final_df_accept)}\")\n",
    "\n",
    "# --- Processing Rejected Repositories ---\n",
    "print(\"\\n--- Processing Rejected Repositories ---\")\n",
    "final_df_reject = finalize_dataframe(\n",
    "    pr_readability_df_reject, \n",
    "    \"issue_pr_readability_rejected.csv\" # Save to a separate file\n",
    ")\n",
    "\n",
    "print(\"\\nRejected Repository Metrics DataFrame Created:\")\n",
    "print(f\"Total rows in Rejected DataFrame: {len(final_df_reject)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
