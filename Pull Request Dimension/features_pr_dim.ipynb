{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "149048ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad63276",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"./api_key.env\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2df0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repositories\n",
    "repo_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/repository.parquet\")\n",
    "\n",
    "# Pull Request\n",
    "pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89954997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the repository data for 'Java' language\n",
    "java_repo_df = repo_df[repo_df['language'] == 'Java'].copy()\n",
    "java_repo_select_df = java_repo_df[['id', 'full_name']]\n",
    "\n",
    "# Join Repo and PR table based on repo id\n",
    "merged_pr_df = pr_df.merge(\n",
    "    java_repo_select_df,\n",
    "    left_on='repo_id',\n",
    "    right_on='id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# clean up extra attribute\n",
    "merged_pr_df = merged_pr_df.drop(columns=['id_y'])\n",
    "merged_pr_df = merged_pr_df.rename(columns={'id_x':'id'})\n",
    "\n",
    "# Filter PRs that were rejected (not merged) and create a new attribute\n",
    "accepted_prs = merged_pr_df[merged_pr_df['merged_at'].notnull()]\n",
    "rejected_prs = merged_pr_df[merged_pr_df['merged_at'].isnull()]\n",
    "\n",
    "# Prepare for Merge: Rename the key column\n",
    "accepted_prs = accepted_prs[['full_name', 'number']]\n",
    "rejected_prs = rejected_prs[['full_name', 'number']]\n",
    "\n",
    "# print to csv for checking\n",
    "accepted_prs.to_csv(\"accepted_PR.csv\", index=False)\n",
    "rejected_prs.to_csv(\"rejected_PR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14daec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dotCMS', 'core', 32609), ('apache', 'pulsar', 24542), ('dotCMS', 'core', 32771), ('dotCMS', 'core', 32561), ('microsoft', 'ApplicationInsights-Java', 4293)]\n",
      "[('dotCMS', 'core', 32656), ('dotCMS', 'core', 32657), ('dotCMS', 'core', 32658), ('dotCMS', 'core', 32659), ('dotCMS', 'core', 32660)]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Split the name and put it in a List of Dict (not needed but ehh accidentally made the method like that)\n",
    "# ============================================================\n",
    "def process_repositories(pr_df):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame by status, splits the full_name, and creates a \n",
    "    list of (owner, repo) tuples for processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Split the 'full_name' column into 'owner' and 'repo' columns\n",
    "    split_df = pr_df['full_name'].str.split('/', n=1, expand=True)\n",
    "    split_df.columns = ['owner', 'repo']\n",
    "    \n",
    "    # 2. Combine the split columns and the 'number' column into a list of tuples\n",
    "    # We use axis=1 to apply the tuple creation row-wise across the three columns\n",
    "    repositories = pd.concat([split_df, pr_df['number']], axis=1).apply(tuple, axis=1).tolist()\n",
    "    \n",
    "    # Print the first 5 results for verification\n",
    "    print(repositories[:5])\n",
    "    \n",
    "    return repositories\n",
    "\n",
    "\n",
    "ACCEPTED_PULL_REQUEST = process_repositories(accepted_prs)\n",
    "REJECTED_PULL_REQUEST = process_repositories(rejected_prs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data retrieval... (may take a moment due to multiple API calls)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Total reviews (not inline) for a PR\n",
    "# ============================================================\n",
    "def get_review_count(owner: str, repo: str, pr_number: int, headers: Dict) -> int:\n",
    "    \"\"\"Retrieves the total count of formal reviews submitted for a Pull Request using the dedicated /reviews endpoint.\"\"\"\n",
    "    reviews_url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}/reviews\"\n",
    "    \n",
    "    try:\n",
    "        # We use a HEAD request with per_page=1 and pagination trick to get the total count\n",
    "        response = requests.head(reviews_url, headers=headers, params={\"per_page\": 1}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Check the 'Link' header for the last page\n",
    "        link_header = response.headers.get('Link')\n",
    "        if link_header:\n",
    "            last_page_match = re.search(r'page=(\\d+)>; rel=\"last\"', link_header)\n",
    "            if last_page_match:\n",
    "                return int(last_page_match.group(1))\n",
    "        \n",
    "    except requests.exceptions.RequestException:\n",
    "        return 0\n",
    "\n",
    "# ============================================================\n",
    "# Helper: Path files of a repo\n",
    "# ============================================================\n",
    "def get_file_path_metrics(owner: str, repo: str, pr_number: int, headers: Dict) -> Tuple[int, float, int]:\n",
    "    \"\"\"\n",
    "    Retrieves the count of changed files and calculates file path length statistics.\n",
    "    Returns: (total_files, avg_path_length, max_path_length)\n",
    "    \"\"\"\n",
    "    files_url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}/files\"\n",
    "    all_file_paths = []\n",
    "    page = 1\n",
    "    \n",
    "    # \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                files_url, \n",
    "                headers=headers, \n",
    "                params={\"per_page\": 100, \"page\": page}, \n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            files_data = response.json()\n",
    "            \n",
    "            if not files_data:\n",
    "                break\n",
    "                \n",
    "            # Extract the 'filename' (which includes the full path)\n",
    "            for file in files_data:\n",
    "                # Store the length of the full file path string\n",
    "                all_file_paths.append(len(file.get('filename', ''))) \n",
    "            \n",
    "            # Check for the next page\n",
    "            if 'link' not in response.headers or 'rel=\"next\"' not in response.headers['link']:\n",
    "                break\n",
    "            page += 1\n",
    "            \n",
    "        except requests.exceptions.RequestException:\n",
    "            break\n",
    "            \n",
    "    num_paths = len(all_file_paths)\n",
    "    \n",
    "    if num_paths == 0:\n",
    "        return 0, 0.0, 0\n",
    "    \n",
    "    # Calculate average and max path length\n",
    "    avg_path_length = sum(all_file_paths) / num_paths\n",
    "    max_path_length = max(all_file_paths)\n",
    "    \n",
    "    return num_paths, avg_path_length, max_path_length\n",
    "\n",
    "# ============================================================\n",
    "# Main Function: Pull Request Metrics\n",
    "# ============================================================\n",
    "def get_pull_request_metrics(owner: str, repo: str, pr_number: int, github_token: Optional[str] = None) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieves the lines added, lines deleted, and the number of files changed\n",
    "    for a specific GitHub Pull Request.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. API URL for a specific Pull Request\n",
    "    pr_url = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}\"\n",
    "    \n",
    "    headers = {\n",
    "        # Standard Accept header for the V3 API\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    if github_token:\n",
    "        headers[\"Authorization\"] = f\"token {github_token}\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch the Pull Request object\n",
    "        response = requests.get(pr_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        pr_data = response.json()\n",
    "\n",
    "        # 1. Line/File Change Metrics (from previous step)\n",
    "        num_additions = pr_data.get('additions', 0)\n",
    "        num_deletions = pr_data.get('deletions', 0)\n",
    "        num_files_changed = pr_data.get('changed_files', 0)\n",
    "        \n",
    "        # 2. NumCommits, NumComments (exclude review) \n",
    "        num_commits = pr_data.get('commits', 0)\n",
    "        num_comments = pr_data.get('comments', 0)\n",
    "        num_formal_reviews = get_review_count(owner, repo, pr_number, headers)\n",
    "        num_inline_comments = pr_data.get('review_comments', 0)\n",
    "        \n",
    "        #3\n",
    "        num_paths, avg_path_len, max_path_len = get_file_path_metrics(\n",
    "            owner, repo, pr_number, headers\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"PR_ID\": pr_number,\n",
    "            \"Additions\": num_additions,\n",
    "            \"Deletions\": num_deletions,\n",
    "            \"Files_Changed\": num_files_changed,\n",
    "            \"NumCommits\": num_commits,\n",
    "            \"NumComments\": num_comments,\n",
    "            \"NumFormalReviews\": num_formal_reviews, \n",
    "            \"NumInlineComments\": num_inline_comments, \n",
    "            \"NumPathsInFile\": num_paths,          # The number of paths (or files changed)\n",
    "            \"AvgPathCharLength\": avg_path_len,    # Average characters in file paths\n",
    "            \"MaxPathCharLength\": max_path_len,    # Max characters in file paths\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data for PR #{pr_number} in {owner}/{repo}: {e}\")\n",
    "            return None\n",
    "        \n",
    "# ============================================================\n",
    "# Main Helper: Fetch the main metric functions \n",
    "# ============================================================\n",
    "def fetch_metrics(repo_list, token):\n",
    "    results = []\n",
    "    # limit the number of repositories processed here for testing REPOSITORIES[:10]:\n",
    "    for owner, repo, pr_number in repo_list: # Apply the test limit here\n",
    "        metrics = get_pull_request_metrics(owner, repo, pr_number, token)\n",
    "        if metrics:\n",
    "            results.append(metrics)\n",
    "    \n",
    "    # Create the Metric DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROGRAM\n",
    "# ============================================================\n",
    "print(\"\\nStarting data retrieval... (may take a moment due to multiple API calls)\")\n",
    "pr_metrics_df_accept = fetch_metrics(ACCEPTED_PULL_REQUEST, GITHUB_TOKEN)\n",
    "pr_metrics_df_reject = fetch_metrics(REJECTED_PULL_REQUEST, GITHUB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2897b9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR_ID</th>\n",
       "      <th>Additions</th>\n",
       "      <th>Deletions</th>\n",
       "      <th>Files_Changed</th>\n",
       "      <th>NumCommits</th>\n",
       "      <th>NumComments</th>\n",
       "      <th>NumFormalReviews</th>\n",
       "      <th>NumInlineComments</th>\n",
       "      <th>NumPathsInFile</th>\n",
       "      <th>AvgPathCharLength</th>\n",
       "      <th>MaxPathCharLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32656</td>\n",
       "      <td>2703</td>\n",
       "      <td>546</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>75.960000</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32657</td>\n",
       "      <td>3811</td>\n",
       "      <td>906</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>75.611111</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32658</td>\n",
       "      <td>19214</td>\n",
       "      <td>2952</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>82.117647</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32659</td>\n",
       "      <td>21977</td>\n",
       "      <td>3267</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>81.329730</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32660</td>\n",
       "      <td>25559</td>\n",
       "      <td>4991</td>\n",
       "      <td>197</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>80.543147</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PR_ID  Additions  Deletions  Files_Changed  NumCommits  NumComments  \\\n",
       "0  32656       2703        546             25           2            1   \n",
       "1  32657       3811        906             18           1            3   \n",
       "2  32658      19214       2952            170           8            6   \n",
       "3  32659      21977       3267            185           9            6   \n",
       "4  32660      25559       4991            197          10            7   \n",
       "\n",
       "   NumFormalReviews  NumInlineComments  NumPathsInFile  AvgPathCharLength  \\\n",
       "0               6.0                  2              25          75.960000   \n",
       "1               NaN                  0              18          75.611111   \n",
       "2               NaN                  0             170          82.117647   \n",
       "3               NaN                  0             185          81.329730   \n",
       "4               NaN                  0             197          80.543147   \n",
       "\n",
       "   MaxPathCharLength  \n",
       "0                 90  \n",
       "1                 88  \n",
       "2                114  \n",
       "3                114  \n",
       "4                114  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pr_metrics_df_reject.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Accepted Repositories ---\n",
      "\n",
      "Accepted Repository Metrics DataFrame Created:\n",
      "Total rows in Accepted DataFrame: 10\n",
      "\n",
      "--- Processing Rejected Repositories ---\n",
      "\n",
      "Rejected Repository Metrics DataFrame Created:\n",
      "Total rows in Rejected DataFrame: 10\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: Finalize the dataframe, adding stars and forks\n",
    "# ============================================================\n",
    "def finalize_dataframe(metrics_df, repo_df, output_filename):\n",
    "    \"\"\"\n",
    "    Applies the merging, cleaning, renaming, and reordering steps \n",
    "    to a single metrics DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the rename mapping\n",
    "    rename_map = {\n",
    "        'PR_ID': 'PR_number',\n",
    "        'NumCommits': 'Commits', \n",
    "        'NumComments': 'Comments', \n",
    "        'NumFormalReviews': 'Formal_Review', \n",
    "        'NumInlineComments': 'Inline_Comments_Review'\n",
    "    }\n",
    "    final_df = metrics_df.rename(columns=rename_map)\n",
    "\n",
    "    # 3. Define the final column order\n",
    "    column_order = [\n",
    "        'Commits', 'Additions', 'Deletions', 'Files_Changed', 'Comments', 'Formal_Review', \n",
    "        'Inline_Comments_Review', 'NumPathsInFile', 'AvgPathCharLength', 'MaxPathCharLength', \n",
    "    ]\n",
    "    \n",
    "    # Apply the final column order\n",
    "    final_df = final_df[column_order]\n",
    "    metrics_df = metrics_df.fillna(0.0)\n",
    "\n",
    "    # 4. Save the file (using CSV as per your original request)\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PROGRAM - Separate Processing\n",
    "# ============================================================\n",
    "\n",
    "# --- Processing Accepted Repositories ---\n",
    "print(\"\\n--- Processing Accepted Repositories ---\")\n",
    "final_df_accept = finalize_dataframe(\n",
    "    pr_metrics_df_accept, \n",
    "    repo_df, \n",
    "    \"pr_metrics_accepted.csv\" # Save to a separate file\n",
    ")\n",
    "\n",
    "print(\"\\nAccepted Repository Metrics DataFrame Created:\")\n",
    "print(f\"Total rows in Accepted DataFrame: {len(final_df_accept)}\")\n",
    "\n",
    "# --- Processing Rejected Repositories ---\n",
    "print(\"\\n--- Processing Rejected Repositories ---\")\n",
    "final_df_reject = finalize_dataframe(\n",
    "    pr_metrics_df_reject, \n",
    "    repo_df, \n",
    "    \"pr_metrics_rejected.csv\" # Save to a separate file\n",
    ")\n",
    "\n",
    "print(\"\\nRejected Repository Metrics DataFrame Created:\")\n",
    "print(f\"Total rows in Rejected DataFrame: {len(final_df_reject)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
